{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "404757a0",
   "metadata": {},
   "source": [
    "# Select data day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "622dc3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from decimal import Decimal\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math \n",
    "from typing import List, Union, Optional\n",
    "from astropy.time import Time\n",
    "import missingno as msno\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def open_ErYb_data(data_path):\n",
    "    key2read = [\"MJD\", \"timer\", \"SDR:frep_ErYb\", \"fo_ErYb\", \"fb_Si_ErYb\", \"fb_Yb_ErYb\", \"fb_Al_ErYb\"] \n",
    "    types = {key: str for key in key2read}\n",
    "    types[\"MJD\"] = float\n",
    " \n",
    "    data = pd.read_csv(data_path, header=1, delimiter=\"\\t\", dtype=types, engine=\"python\")\n",
    " \n",
    "    for k in key2read:\n",
    "        data[k] = data[k].apply(Decimal)\n",
    " \n",
    "    data.index = range(len(data))\n",
    " \n",
    "    return data[list(types.keys())]\n",
    "\n",
    "def open_shiftfile_Al(datapath):\n",
    "    data = pd.read_csv(datapath, header=30, delimiter=\"\\t\", dtype={1: str}, engine=\"python\")\n",
    " \n",
    "    data.columns = [\"MJD\", \"shift\", \"IS_GOOD\"]\n",
    " \n",
    "    data[\"IS_GOOD\"] = data[\"IS_GOOD\"].apply(lambda x: x == 1.0)\n",
    " \n",
    "    data.loc[~data[\"IS_GOOD\"], \"shift\"] = np.nan\n",
    " \n",
    "    data[\"shift\"] = data[\"shift\"].apply(float)\n",
    " \n",
    "    return data\n",
    "\n",
    "def open_shiftfile_Sr(datapath): ##Note: assuming (unverified) that for days_irregular all Sr .dat files have this format.... \n",
    "    data = pd.read_csv(datapath, header=24, delimiter=\"\\t\", dtype={1: str}, engine=\"python\")\n",
    "\n",
    "    data.columns = [\"MJD\", \"shift\", \"IS_GOOD\"]\n",
    " \n",
    "    data[\"IS_GOOD\"] = data[\"IS_GOOD\"].apply(lambda x: x == 1.0)\n",
    " \n",
    "    data.loc[~data[\"IS_GOOD\"], \"shift\"] = np.nan\n",
    " \n",
    "    data[\"shift\"] = data[\"shift\"].apply(float)\n",
    " \n",
    "    return data\n",
    " \n",
    "def open_shiftfile_Yb(datapath):\n",
    "    data = pd.read_csv(datapath, header=8, delimiter=r\"\\t\",  dtype={1: str}, engine=\"python\")\n",
    " \n",
    "    data.columns = [\"MJD\", \"shift\", \"IS_GOOD\"]\n",
    " \n",
    "    data[\"IS_GOOD\"] = data[\"IS_GOOD\"].apply(lambda x: x == 1.0)\n",
    " \n",
    "    data.loc[~data[\"IS_GOOD\"], \"shift\"] = np.nan\n",
    " \n",
    "    data[\"shift\"] = data[\"shift\"].apply(float)\n",
    " \n",
    "    return data\n",
    " \n",
    "def open_maser_correction(datapath):\n",
    "    data = pd.read_csv(datapath, header=1, delimiter=\",\", dtype={1: str}, engine=\"python\")\n",
    " \n",
    "    data.columns = [\"date\", \"maser_offset\"]\n",
    " \n",
    "    data[\"date\"] = data[\"date\"].apply(str)#.str.split(\"-\").str.join(\"\")\n",
    "    data[\"maser_offset\"] = data[\"maser_offset\"].apply(float)\n",
    " \n",
    "    return data\n",
    "\n",
    "## ? YbSr ratio for all 13 days \n",
    "## ? AlYb and AlSr ratio only for 9 of the 13 days \n",
    "path = \"/Users/smt3/Documents/GitHub/2025 clock comparison data/\"\n",
    "days = [20250116, 20250124, 20250204, 20250227, 20250304, 20250307, 20250318]\n",
    "days = list(map(str, days))\n",
    "day_index = 0 \n",
    "\n",
    "days_irregular = [20250206, 20250228, 20250306, 20250313, 20250320, 20250321]\n",
    "days_irregular = list(map(str, days_irregular))\n",
    "day_irregular_index = 1 #None ##set to None if analyzing days, set to 0:5 if analyzing days_irregular\n",
    "\n",
    "## For days_irregular, read in Sr data with the following \n",
    "if day_irregular_index != None:\n",
    "    if days_irregular[day_irregular_index] == 20250206:\n",
    "        shift_data_Sr = pd.concat(\n",
    "            [\n",
    "                open_shiftfile_Sr(path + days_irregular[day_irregular_index] + \"/\" + days_irregular[day_irregular_index] + \"_clock_lock0.dat\"),\n",
    "                open_shiftfile_Sr(path + days_irregular[day_irregular_index] + \"/\" + days_irregular[day_irregular_index] + \"_clock_lock2.dat\"),\n",
    "            ],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "    elif days_irregular[day_irregular_index] == 20250228:\n",
    "        shift_data_Sr = open_shiftfile_Sr(path + days_irregular[day_irregular_index] + \"/\" + days_irregular[day_irregular_index] + \"_clock_lock1.dat\")\n",
    "    elif days_irregular[day_irregular_index] == 20250306:\n",
    "        shift_data_Sr = open_shiftfile_Sr(path + days_irregular[day_irregular_index] + \"/\" + days_irregular[day_irregular_index] + \"_clock_lock2.dat\")\n",
    "    elif days_irregular[day_irregular_index] == 20250313:\n",
    "        shift_data_Sr = pd.concat(\n",
    "            [\n",
    "                open_shiftfile_Sr(path + days_irregular[day_irregular_index] + \"/\" + days_irregular[day_irregular_index] + \"_clock_lock0.dat\"),\n",
    "                open_shiftfile_Sr(path + days_irregular[day_irregular_index] + \"/\" + days_irregular[day_irregular_index] + \"_clock_lock1.dat\"),\n",
    "                open_shiftfile_Sr(path + days_irregular[day_irregular_index] + \"/\" + days_irregular[day_irregular_index] + \"_clock_lock2.dat\"),\n",
    "                open_shiftfile_Sr(path + days_irregular[day_irregular_index] + \"/\" + days_irregular[day_irregular_index] + \"_clock_lock3.dat\"),\n",
    "            ],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "    elif days_irregular[day_irregular_index] == 20250320:\n",
    "        shift_data_Sr = pd.concat(\n",
    "            [\n",
    "                open_shiftfile_Sr(path + days_irregular[day_irregular_index] + \"/\" + days_irregular[day_irregular_index] + \"_clock_lock0.dat\"),\n",
    "                open_shiftfile_Sr(path + days_irregular[day_irregular_index] + \"/\" + days_irregular[day_irregular_index] + \"_clock_lock2.dat\"),\n",
    "                open_shiftfile_Sr(path + days_irregular[day_irregular_index] + \"/\" + days_irregular[day_irregular_index] + \"_clock_lock4.dat\"),\n",
    "            ],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "    elif days_irregular[day_irregular_index] == 20250321:\n",
    "        shift_data_Sr = pd.concat(\n",
    "            [\n",
    "                open_shiftfile_Sr(path + days_irregular[day_irregular_index] + \"/\" + days_irregular[day_irregular_index] + \"_clock_lock0.dat\"),\n",
    "                open_shiftfile_Sr(path + days_irregular[day_irregular_index] + \"/\" + days_irregular[day_irregular_index] + \"_clock_lock1.dat\"),\n",
    "            ],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "else: \n",
    "    shift_data_Sr = open_shiftfile_Sr(path + days[day_index] + \"/\" + days[day_index] + \"_clock_lock0.dat\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d652ed54",
   "metadata": {},
   "source": [
    "# Read in data and corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "19655975",
   "metadata": {},
   "outputs": [],
   "source": [
    "maser_corrections = open_maser_correction(path + \"daily maser offsets.csv\")\n",
    "\n",
    "if day_irregular_index != None:\n",
    "    data_ErYb = open_ErYb_data(path + days_irregular[day_irregular_index] + \"/\" + days_irregular[day_irregular_index] + \"_Deglitched_ErYb_only.dat\") \n",
    "    shift_data_Al = open_shiftfile_Al(path + days_irregular[day_irregular_index] + \"/\" + days_irregular[day_irregular_index] + \"_Alp_Freq_Shifts_ErYb.dat\")\n",
    "    shift_data_Yb = open_shiftfile_Yb(path + days_irregular[day_irregular_index] + \"/YbI_1_rerun.txt\")\n",
    "else:\n",
    "    data_ErYb = open_ErYb_data(path + days[day_index] + \"/\" + days[day_index] + \"_Deglitched_ErYb_only.dat\") \n",
    "    shift_data_Al = open_shiftfile_Al(path + days[day_index] + \"/\" + days[day_index] + \"_Alp_Freq_Shifts_ErYb.dat\")\n",
    "    shift_data_Yb = open_shiftfile_Yb(path + days[day_index] + \"/YbI_1_rerun.txt\")\n",
    "\n",
    "\n",
    "def compute_nuAl_ErYb(data):\n",
    "    data[\"nuAl\"] = -Decimal(\"105e6\") + Decimal(\"560444\") * (Decimal(\"1e9\") + data[\"SDR:frep_ErYb\"]) / Decimal(2) - data[\"fb_Al_ErYb\"]\n",
    "    data[\"nuAl\"] = Decimal(4) * data[\"nuAl\"]   \n",
    "\n",
    "def compute_nuSr_ErYb(data):\n",
    "    data[\"nuSi\"] = -Decimal(\"105e6\") + Decimal(\"388752\") * (Decimal(\"1e9\") + data[\"SDR:frep_ErYb\"]) / Decimal(2) - Decimal(\"100e6\")\n",
    "    data[\"nuSr\"] = (Decimal(\"1716882\") / Decimal(\"777577\")) * (data[\"nuSi\"] - Decimal(\"216e6\"))\n",
    "\n",
    "def compute_nuYb_ErYb(data):\n",
    "    data[\"nuYb\"] = -Decimal(\"105e6\") + Decimal(\"518237\") * (Decimal(\"1e9\") + data[\"SDR:frep_ErYb\"]) / Decimal(2) - data[\"fb_Yb_ErYb\"]\n",
    "    data[\"nuYb\"] = Decimal(2) * data[\"nuYb\"] \n",
    "\n",
    "compute_nuAl_ErYb(data_ErYb)\n",
    "compute_nuSr_ErYb(data_ErYb)\n",
    "compute_nuYb_ErYb(data_ErYb) \n",
    "\n",
    "YbSrRatio2020 = Decimal(\"1.2075070393433378482\") \n",
    "AlYbRatio2020 = Decimal(\"2.162887127516663703\")\n",
    "AlSrRatio2020 = Decimal(\"2.611701431781463025\")\n",
    " \n",
    "if day_irregular_index != None:\n",
    "    correction_condition = days_irregular[day_irregular_index] == maser_corrections[\"date\"]\n",
    "else: \n",
    "    correction_condition = days[day_index] == maser_corrections[\"date\"]\n",
    "masercorrection = maser_corrections[correction_condition][\"maser_offset\"].apply(Decimal)\n",
    "\n",
    "GR_shift_Al = Decimal(\"-8.114e-16\") \n",
    "GR_shift_Yb = Decimal(\"-8.109e-16\")\n",
    "GR_shift_Sr = Decimal(\"10.660e-16\")\n",
    "GR_shift_sea_level = Decimal(\"-1798.501e-16\")\n",
    "\n",
    "total_correction_Yb = Decimal(\"1\") + GR_shift_Yb + GR_shift_sea_level + masercorrection\n",
    "total_correction_Sr = Decimal(\"1\") + GR_shift_Sr + GR_shift_sea_level + masercorrection\n",
    "total_correction_Al = Decimal(\"1\") + GR_shift_Al + GR_shift_sea_level + masercorrection\n",
    "# print(total_correction_Yb)\n",
    "# print(total_correction_Sr)\n",
    "# print(total_correction_Al)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26513bf3",
   "metadata": {},
   "source": [
    "# Use only good data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5f76cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "al_cond = ~shift_data_Al['shift'].isna()\n",
    "Al_non_na = shift_data_Al[al_cond]\n",
    "Al = pd.Series(Al_non_na['MJD'])\n",
    "\n",
    "sr_cond = ~shift_data_Sr['shift'].isna()\n",
    "Sr_non_na = shift_data_Sr[sr_cond]\n",
    "Sr = pd.Series(Sr_non_na['MJD'])\n",
    "\n",
    "yb_cond = ~shift_data_Yb['shift'].isna()\n",
    "Yb_non_na = shift_data_Yb[yb_cond]\n",
    "Yb = pd.Series(Yb_non_na['MJD']) \n",
    "\n",
    "comb_condition = (~data_ErYb['nuAl'].isna() & ~data_ErYb['nuSr'].isna() & ~data_ErYb['nuYb'].isna())\n",
    "comb_full = data_ErYb[comb_condition]\n",
    "\n",
    "good_condition_al = Al_non_na[\"IS_GOOD\"] == 1\n",
    "shift_data_Al_good = Al_non_na[good_condition_al].reset_index(drop=True, inplace = False)\n",
    "Al_good = pd.Series(shift_data_Al_good['MJD'])\n",
    "\n",
    "good_condition_sr = Sr_non_na[\"IS_GOOD\"] == 1\n",
    "shift_data_Sr_good = Sr_non_na[good_condition_sr].reset_index(drop=True, inplace = False)\n",
    "Sr_good = pd.Series(shift_data_Sr_good['MJD'])\n",
    "\n",
    "good_condition_yb = Yb_non_na[\"IS_GOOD\"] == 1\n",
    "shift_data_Yb_good = Yb_non_na[good_condition_yb].reset_index(drop=True, inplace = False)\n",
    "Yb_good = pd.Series(shift_data_Yb_good['MJD']) \n",
    "\n",
    "len_comb = len(comb_full['MJD']) \n",
    "len_Al = len(shift_data_Al_good['shift'])        \n",
    "len_Sr = len(shift_data_Sr_good['shift'])        \n",
    "len_Yb = len(shift_data_Yb_good['shift'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4266907f",
   "metadata": {},
   "source": [
    "# Overlapping window of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c901a5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comb start and end MJD: [ 60734.753570 ,  60735.012380 ]\n",
      "Al good shift start and end MJD: [ 60734.7766551 ,  60734.9880324 ]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[67]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mComb start and end MJD: [\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m'\u001b[39m\u001b[38;5;132;01m{:0.11}\u001b[39;00m\u001b[33m'\u001b[39m.format(comb_full[\u001b[33m'\u001b[39m\u001b[33mMJD\u001b[39m\u001b[33m'\u001b[39m].iloc[\u001b[32m0\u001b[39m]), \u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[38;5;132;01m{:0.11}\u001b[39;00m\u001b[33m'\u001b[39m.format(comb_full[\u001b[33m'\u001b[39m\u001b[33mMJD\u001b[39m\u001b[33m'\u001b[39m].iloc[len_comb-\u001b[32m1\u001b[39m]), \u001b[33m'\u001b[39m\u001b[33m]\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAl good shift start and end MJD: [\u001b[39m\u001b[33m\"\u001b[39m, shift_data_Al_good[\u001b[33m'\u001b[39m\u001b[33mMJD\u001b[39m\u001b[33m'\u001b[39m].iloc[\u001b[32m0\u001b[39m], \u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m, shift_data_Al_good[\u001b[33m'\u001b[39m\u001b[33mMJD\u001b[39m\u001b[33m'\u001b[39m].iloc[len_Al-\u001b[32m1\u001b[39m], \u001b[33m'\u001b[39m\u001b[33m]\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSr good shift start and end MJD: [\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mshift_data_Sr_good\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mMJD\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m, shift_data_Sr_good[\u001b[33m'\u001b[39m\u001b[33mMJD\u001b[39m\u001b[33m'\u001b[39m].iloc[len_Sr-\u001b[32m1\u001b[39m], \u001b[33m'\u001b[39m\u001b[33m]\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mYb good shift start and end MJD: [\u001b[39m\u001b[33m\"\u001b[39m, shift_data_Yb_good[\u001b[33m'\u001b[39m\u001b[33mMJD\u001b[39m\u001b[33m'\u001b[39m].iloc[\u001b[32m0\u001b[39m], \u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m, shift_data_Yb_good[\u001b[33m'\u001b[39m\u001b[33mMJD\u001b[39m\u001b[33m'\u001b[39m].iloc[len_Yb-\u001b[32m1\u001b[39m], \u001b[33m'\u001b[39m\u001b[33m]\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      7\u001b[39m starts = [comb_full[\u001b[33m'\u001b[39m\u001b[33mMJD\u001b[39m\u001b[33m'\u001b[39m].iloc[\u001b[32m0\u001b[39m], shift_data_Al_good[\u001b[33m'\u001b[39m\u001b[33mMJD\u001b[39m\u001b[33m'\u001b[39m].iloc[\u001b[32m0\u001b[39m], shift_data_Sr_good[\u001b[33m'\u001b[39m\u001b[33mMJD\u001b[39m\u001b[33m'\u001b[39m].iloc[\u001b[32m0\u001b[39m], shift_data_Yb_good[\u001b[33m'\u001b[39m\u001b[33mMJD\u001b[39m\u001b[33m'\u001b[39m].iloc[\u001b[32m0\u001b[39m]] \n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/myvenv/lib/python3.12/site-packages/pandas/core/indexing.py:1191\u001b[39m, in \u001b[36m_LocationIndexer.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1189\u001b[39m maybe_callable = com.apply_if_callable(key, \u001b[38;5;28mself\u001b[39m.obj)\n\u001b[32m   1190\u001b[39m maybe_callable = \u001b[38;5;28mself\u001b[39m._check_deprecated_callable_usage(key, maybe_callable)\n\u001b[32m-> \u001b[39m\u001b[32m1191\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/myvenv/lib/python3.12/site-packages/pandas/core/indexing.py:1752\u001b[39m, in \u001b[36m_iLocIndexer._getitem_axis\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCannot index by location index with a non-integer key\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1751\u001b[39m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1752\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1754\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj._ixs(key, axis=axis)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/myvenv/lib/python3.12/site-packages/pandas/core/indexing.py:1685\u001b[39m, in \u001b[36m_iLocIndexer._validate_integer\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1683\u001b[39m len_axis = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.obj._get_axis(axis))\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m key >= len_axis \u001b[38;5;129;01mor\u001b[39;00m key < -len_axis:\n\u001b[32m-> \u001b[39m\u001b[32m1685\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33msingle positional indexer is out-of-bounds\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mIndexError\u001b[39m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "##TODO: generalize this to look for paired windows (rather than one window amongst all three)\n",
    "print(\"Comb start and end MJD: [\", '{:0.11}'.format(comb_full['MJD'].iloc[0]), ', ', '{:0.11}'.format(comb_full['MJD'].iloc[len_comb-1]), ']')\n",
    "print(\"Al good shift start and end MJD: [\", shift_data_Al_good['MJD'].iloc[0], ', ', shift_data_Al_good['MJD'].iloc[len_Al-1], ']')\n",
    "print(\"Sr good shift start and end MJD: [\", shift_data_Sr_good['MJD'].iloc[0], ', ', shift_data_Sr_good['MJD'].iloc[len_Sr-1], ']')\n",
    "print(\"Yb good shift start and end MJD: [\", shift_data_Yb_good['MJD'].iloc[0], ', ', shift_data_Yb_good['MJD'].iloc[len_Yb-1], ']')\n",
    "\n",
    "starts = [comb_full['MJD'].iloc[0], shift_data_Al_good['MJD'].iloc[0], shift_data_Sr_good['MJD'].iloc[0], shift_data_Yb_good['MJD'].iloc[0]] \n",
    "ends = [comb_full['MJD'].iloc[len_comb-1], shift_data_Al_good['MJD'].iloc[len_Al-1], shift_data_Sr_good['MJD'].iloc[len_Sr-1], shift_data_Yb_good['MJD'].iloc[len_Yb-1]] \n",
    "\n",
    "last_start_time = max(starts)\n",
    "first_end_time = min(ends)\n",
    "\n",
    "print(\"Last start time: \", last_start_time)\n",
    "print(\"First end time: \", first_end_time)\n",
    "\n",
    "def lb_extract(target, data):\n",
    "    inx = 0\n",
    "    stopper = 1\n",
    "    while stopper == 1:\n",
    "        if data.iloc[inx] < target:\n",
    "            inx += 1\n",
    "        else:\n",
    "            return inx  \n",
    "\n",
    "def ub_extract(target, data):\n",
    "    inx = 1\n",
    "    stopper = 1\n",
    "    while stopper == 1:\n",
    "        if data.iloc[len(data)-inx] > target:\n",
    "            inx += 1\n",
    "        else:\n",
    "            return len(data)-inx \n",
    "\n",
    "comb_start = ub_extract(target = last_start_time, data = comb_full['MJD'])  \n",
    "comb_end = lb_extract(target = first_end_time, data = comb_full['MJD']) \n",
    "\n",
    "comb = pd.DataFrame()\n",
    "comb[\"MJD\"] = comb_full['MJD'].iloc[comb_start:comb_end] \n",
    "comb[\"nuAl\"] = comb_full['nuAl'].iloc[comb_start:comb_end]\n",
    "comb[\"nuSr\"] = comb_full['nuSr'].iloc[comb_start:comb_end]\n",
    "comb[\"nuYb\"] = comb_full['nuYb'].iloc[comb_start:comb_end]\n",
    "comb.reset_index(drop=True, inplace=True)\n",
    "\n",
    "al_start = ub_extract(target = last_start_time, data = shift_data_Al_good[\"MJD\"])\n",
    "al_end = lb_extract(target = first_end_time, data = shift_data_Al_good[\"MJD\"])  \n",
    "shift_data_Al = shift_data_Al_good[al_start:al_end] \n",
    "shift_data_Al.reset_index(drop=True, inplace=True)\n",
    "\n",
    "sr_start = ub_extract(target = last_start_time, data = shift_data_Sr_good[\"MJD\"])\n",
    "sr_end = lb_extract(target = first_end_time, data = shift_data_Sr_good[\"MJD\"])  \n",
    "shift_data_Sr = shift_data_Sr_good[sr_start:sr_end]\n",
    "shift_data_Sr.reset_index(drop=True, inplace=True)\n",
    "\n",
    "yb_start = ub_extract(target = last_start_time, data = shift_data_Yb_good[\"MJD\"])\n",
    "yb_end = lb_extract(target = first_end_time, data = shift_data_Yb_good[\"MJD\"])  \n",
    "shift_data_Yb = shift_data_Yb_good[yb_start:yb_end]\n",
    "shift_data_Yb.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"nuAl, nuSr, and nuYb start and end MJD: [\", '{:0.11}'.format(comb[\"MJD\"].iloc[0]), ', ', '{:0.11}'.format(comb[\"MJD\"].iloc[len(comb[\"MJD\"])-1]), ']')\n",
    "print(\"Al good shift start and end MJD: [\", shift_data_Al['MJD'].iloc[0], ', ', shift_data_Al['MJD'].iloc[len(shift_data_Al['MJD'])-1], ']')\n",
    "print(\"Sr good shift start and end MJD: [\", shift_data_Sr['MJD'].iloc[0], ', ', shift_data_Sr['MJD'].iloc[len(shift_data_Sr['MJD'])-1], ']')\n",
    "print(\"Yb good shift start and end MJD: [\", shift_data_Yb['MJD'].iloc[0], ', ', shift_data_Yb['MJD'].iloc[len(shift_data_Yb['MJD'])-1], ']')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4647dd9",
   "metadata": {},
   "source": [
    "# Create datetime index for all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "71a7f2ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input values did not match the format class mjd:\nTypeError: for mjd class, input should be (long) doubles, string, or Decimal, and second values are only allowed for (long) doubles.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/myvenv/lib/python3.12/site-packages/astropy/time/formats.py:558\u001b[39m, in \u001b[36mTimeNumeric._check_val_type\u001b[39m\u001b[34m(self, val1, val2)\u001b[39m\n\u001b[32m    557\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m558\u001b[39m     val1, val2 = \u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/myvenv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:2522\u001b[39m, in \u001b[36mvectorize.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   2520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2522\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_as_normal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/myvenv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:2515\u001b[39m, in \u001b[36mvectorize._call_as_normal\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   2513\u001b[39m     vargs.extend([kwargs[_n] \u001b[38;5;28;01mfor\u001b[39;00m _n \u001b[38;5;129;01min\u001b[39;00m names])\n\u001b[32m-> \u001b[39m\u001b[32m2515\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_vectorize_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/myvenv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:2600\u001b[39m, in \u001b[36mvectorize._vectorize_call\u001b[39m\u001b[34m(self, func, args)\u001b[39m\n\u001b[32m   2599\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2600\u001b[39m     ufunc, otypes = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_ufunc_and_otypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2602\u001b[39m     \u001b[38;5;66;03m# Convert args to object arrays first\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/myvenv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:2556\u001b[39m, in \u001b[36mvectorize._get_ufunc_and_otypes\u001b[39m\u001b[34m(self, func, args)\u001b[39m\n\u001b[32m   2555\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m builtins.any(arg.size == \u001b[32m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args):\n\u001b[32m-> \u001b[39m\u001b[32m2556\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mcannot call `vectorize` on size 0 inputs \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   2557\u001b[39m                      \u001b[33m'\u001b[39m\u001b[33munless `otypes` is set\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   2559\u001b[39m inputs = [arg.flat[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args]\n",
      "\u001b[31mValueError\u001b[39m: cannot call `vectorize` on size 0 inputs unless `otypes` is set",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/myvenv/lib/python3.12/site-packages/astropy/time/core.py:636\u001b[39m, in \u001b[36mTimeBase._get_time_fmt\u001b[39m\u001b[34m(self, val, val2, format, scale, precision, in_subfmt, out_subfmt, mask)\u001b[39m\n\u001b[32m    635\u001b[39m         val, val2 = \u001b[38;5;28mcls\u001b[39m._fill_masked_values(oval, oval2, mask, in_subfmt)\n\u001b[32m--> \u001b[39m\u001b[32m636\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_subfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_subfmt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m UnitConversionError:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/myvenv/lib/python3.12/site-packages/astropy/time/formats.py:170\u001b[39m, in \u001b[36mTimeFormat.__init__\u001b[39m\u001b[34m(self, val1, val2, scale, precision, in_subfmt, out_subfmt, from_jd)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     val1, val2 = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_val_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_jds(val1, val2)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/myvenv/lib/python3.12/site-packages/astropy/time/formats.py:560\u001b[39m, in \u001b[36mTimeNumeric._check_val_type\u001b[39m\u001b[34m(self, val1, val2)\u001b[39m\n\u001b[32m    559\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m560\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    561\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m class, input should be (long) doubles, string, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    562\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mor Decimal, and second values are only allowed for \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    563\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m(long) doubles.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    564\u001b[39m         )\n\u001b[32m    566\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m val1, val2\n",
      "\u001b[31mTypeError\u001b[39m: for mjd class, input should be (long) doubles, string, or Decimal, and second values are only allowed for (long) doubles.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m comb_datetime = comb.copy()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m comb_datetime[\u001b[33m'\u001b[39m\u001b[33mdatetime\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mTime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomb_datetime\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mMJD\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmjd\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m.to_datetime()\n\u001b[32m      3\u001b[39m comb_datetime = comb_datetime.set_index(\u001b[33m'\u001b[39m\u001b[33mdatetime\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m shift_data_Al_datetime = shift_data_Al.copy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/myvenv/lib/python3.12/site-packages/astropy/time/core.py:1984\u001b[39m, in \u001b[36mTime.__init__\u001b[39m\u001b[34m(self, val, val2, format, scale, precision, in_subfmt, out_subfmt, location, copy)\u001b[39m\n\u001b[32m   1982\u001b[39m         \u001b[38;5;28mself\u001b[39m._set_scale(scale)\n\u001b[32m   1983\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1984\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init_from_vals\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1985\u001b[39m \u001b[43m        \u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_subfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_subfmt\u001b[49m\n\u001b[32m   1986\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1987\u001b[39m     \u001b[38;5;28mself\u001b[39m.SCALES = TIME_TYPES[\u001b[38;5;28mself\u001b[39m.scale]\n\u001b[32m   1989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.location \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[32m   1990\u001b[39m     \u001b[38;5;28mself\u001b[39m.location.size > \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.location.shape != \u001b[38;5;28mself\u001b[39m.shape\n\u001b[32m   1991\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/myvenv/lib/python3.12/site-packages/astropy/time/core.py:560\u001b[39m, in \u001b[36mTimeBase._init_from_vals\u001b[39m\u001b[34m(self, val, val2, format, scale, copy, precision, in_subfmt, out_subfmt)\u001b[39m\n\u001b[32m    557\u001b[39m mask = combine_masks([mask1, mask2])\n\u001b[32m    559\u001b[39m \u001b[38;5;66;03m# Parse / convert input values into internal jd1, jd2 based on format\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m560\u001b[39m \u001b[38;5;28mself\u001b[39m._time = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_time_fmt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_subfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_subfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[38;5;28mself\u001b[39m._format = \u001b[38;5;28mself\u001b[39m._time.name\n\u001b[32m    565\u001b[39m \u001b[38;5;66;03m# Hack from #9969 to allow passing the location value that has been\u001b[39;00m\n\u001b[32m    566\u001b[39m \u001b[38;5;66;03m# collected by the TimeAstropyTime format class up to the Time level.\u001b[39;00m\n\u001b[32m    567\u001b[39m \u001b[38;5;66;03m# TODO: find a nicer way.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/myvenv/lib/python3.12/site-packages/astropy/time/core.py:644\u001b[39m, in \u001b[36mTimeBase._get_time_fmt\u001b[39m\u001b[34m(self, val, val2, format, scale, precision, in_subfmt, out_subfmt, mask)\u001b[39m\n\u001b[32m    639\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    640\u001b[39m     \u001b[38;5;66;03m# If ``format`` specified then there is only one possibility, so raise\u001b[39;00m\n\u001b[32m    641\u001b[39m     \u001b[38;5;66;03m# immediately and include the upstream exception message to make it\u001b[39;00m\n\u001b[32m    642\u001b[39m     \u001b[38;5;66;03m# easier for user to see what is wrong.\u001b[39;00m\n\u001b[32m    643\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(formats) == \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    645\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInput values did not match the format class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mformat\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    646\u001b[39m             + os.linesep\n\u001b[32m    647\u001b[39m             + \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    648\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    649\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    650\u001b[39m         problems[name] = err\n",
      "\u001b[31mValueError\u001b[39m: Input values did not match the format class mjd:\nTypeError: for mjd class, input should be (long) doubles, string, or Decimal, and second values are only allowed for (long) doubles."
     ]
    }
   ],
   "source": [
    "comb_datetime = comb.copy()\n",
    "comb_datetime['datetime'] = Time(comb_datetime['MJD'], format = 'mjd').to_datetime()\n",
    "comb_datetime = comb_datetime.set_index('datetime')\n",
    "\n",
    "shift_data_Al_datetime = shift_data_Al.copy()\n",
    "shift_data_Al_datetime['datetime'] = Time(shift_data_Al_datetime['MJD'], format = 'mjd').to_datetime()\n",
    "shift_data_Al_datetime = shift_data_Al_datetime.set_index('datetime')\n",
    "\n",
    "shift_data_Sr_datetime = shift_data_Sr.copy()\n",
    "shift_data_Sr_datetime['datetime'] = Time(shift_data_Sr_datetime['MJD'], format = 'mjd').to_datetime()\n",
    "shift_data_Sr_datetime = shift_data_Sr_datetime.set_index('datetime')\n",
    "\n",
    "shift_data_Yb_datetime = shift_data_Yb.copy()\n",
    "shift_data_Yb_datetime['datetime'] = Time(shift_data_Yb_datetime['MJD'], format = 'mjd').to_datetime()\n",
    "shift_data_Yb_datetime = shift_data_Yb_datetime.set_index('datetime')\n",
    "\n",
    "Al_shift = shift_data_Al_datetime['shift']\n",
    "Sr_shift = shift_data_Sr_datetime['shift']\n",
    "Yb_shift = shift_data_Yb_datetime['shift']\n",
    "\n",
    "interp_times_Al = comb_datetime.index.difference(Al_shift.index) \n",
    "long_Al_index = Al_shift.index.union(interp_times_Al).sort_values()\n",
    "Al_shift_expanded = Al_shift.reindex(long_Al_index)\n",
    "\n",
    "interp_times_Sr = comb_datetime.index.difference(Sr_shift.index) \n",
    "long_Sr_index = Sr_shift.index.union(interp_times_Sr).sort_values()\n",
    "Sr_shift_expanded = Sr_shift.reindex(long_Sr_index)\n",
    "\n",
    "interp_times_Yb = comb_datetime.index.difference(Yb_shift.index) \n",
    "long_Yb_index = Yb_shift.index.union(interp_times_Yb).sort_values()\n",
    "Yb_shift_expanded = Yb_shift.reindex(long_Yb_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae52284",
   "metadata": {},
   "source": [
    "# Necessary supplemental functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a5df233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlapping_avar_fn(y, m): #for computing AVAR from data with missing values \n",
    "    M = len(y)\n",
    "\n",
    "    if M < 2 * m:\n",
    "        raise ValueError(f\"Length of input (M={M}) must be at least 2 * m (2 * {m} = {2 * m})\")\n",
    "\n",
    "    if any(isinstance(v, Decimal) and v.is_nan() for v in y):  \n",
    "        raise ValueError(\"Input y contains NaN values.\")\n",
    "    \n",
    "    if m <= 0:\n",
    "        raise ValueError(\"m must be a positive integer\")\n",
    "\n",
    "    outer_sum = 0\n",
    "\n",
    "    for j in range(0, M - 2 * m + 1):\n",
    "        inner_sum = 0\n",
    "        for i in range(j, j + m):\n",
    "            inner_sum += y[i + m] - y[i]\n",
    "        outer_sum += inner_sum ** 2\n",
    "\n",
    "    result = outer_sum / (2 * m**2 * (M - 2 * m + 1))\n",
    "    return result\n",
    "\n",
    "def clean_frequency_ratio(frequency_ratio_data: List[Optional[Union[float, Decimal]]]) -> List[Union[float, Decimal]]:\n",
    "    return [\n",
    "        x for x in frequency_ratio_data\n",
    "        if x is not None\n",
    "        and not (\n",
    "            (isinstance(x, float) and math.isnan(x)) or\n",
    "            (isinstance(x, Decimal) and x.is_nan())\n",
    "        )\n",
    "    ]\n",
    "\n",
    "def detect_long_missing(data, max_len): #for kalman smoothing interpolation limit \n",
    "    mask = data.isna()\n",
    "    long_gaps = pd.Series(False, index=data.index)\n",
    "\n",
    "    start = None\n",
    "    for i, val in enumerate(mask):\n",
    "        if val and start is None:\n",
    "            start = i\n",
    "        elif not val and start is not None:\n",
    "            if i - start > max_len:\n",
    "                long_gaps[start:i] = True\n",
    "            start = None\n",
    "    if start is not None and len(data) - start > max_len:\n",
    "        long_gaps[start:] = True\n",
    "\n",
    "    return long_gaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cc0a71",
   "metadata": {},
   "source": [
    "# Interpolation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5d626925",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/smt3/Documents/myvenv/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/smt3/Documents/myvenv/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/smt3/Documents/myvenv/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/var/folders/hb/crd62ysx4f1745w1jxnlrch8002d5c/T/ipykernel_217/3281443039.py:50: FutureWarning: Series.interpolate with method=pad is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  Al_shift_interpolated = Al_shift_expanded.interpolate(method=my_method, limit=interp_limit)\n",
      "/var/folders/hb/crd62ysx4f1745w1jxnlrch8002d5c/T/ipykernel_217/3281443039.py:56: FutureWarning: Series.interpolate with method=pad is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  Sr_shift_interpolated = Sr_shift_expanded.interpolate(method=my_method, limit=interp_limit)\n",
      "/var/folders/hb/crd62ysx4f1745w1jxnlrch8002d5c/T/ipykernel_217/3281443039.py:62: FutureWarning: Series.interpolate with method=pad is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  Yb_shift_interpolated = Yb_shift_expanded.interpolate(method=my_method, limit=interp_limit)\n"
     ]
    }
   ],
   "source": [
    "## Create a dictionary to store all six interpolation results \n",
    "interp_Al_results = {} \n",
    "interp_Sr_results = {} \n",
    "interp_Yb_results = {} \n",
    "interp_methods = ['time', 'linear', 'pad', 'nearest', 'cubic', 'kalman']  \n",
    "interp_limit = 10\n",
    "\n",
    "#Kalman setup \n",
    "Al_model = sm.tsa.UnobservedComponents(Al_shift_expanded, level='local level')\n",
    "Sr_model = sm.tsa.UnobservedComponents(Sr_shift_expanded, level='local level')\n",
    "Yb_model = sm.tsa.UnobservedComponents(Yb_shift_expanded, level='local level')\n",
    "\n",
    "Al_result = Al_model.fit(method='lbfgs') \n",
    "Sr_result = Sr_model.fit(method='lbfgs')\n",
    "Yb_result = Yb_model.fit(method='lbfgs')\n",
    "\n",
    "Al_smoothed_level = Al_result.smoothed_state[0]\n",
    "Sr_smoothed_level = Sr_result.smoothed_state[0]\n",
    "Yb_smoothed_level = Yb_result.smoothed_state[0]  \n",
    "\n",
    "for my_method in interp_methods:\n",
    "    if my_method == \"kalman\":\n",
    "        ## kalman specific \n",
    "        Al_shift_interpolated = pd.Series(Al_smoothed_level, index=Al_shift_expanded.index)\n",
    "        Sr_shift_interpolated = pd.Series(Sr_smoothed_level, index=Sr_shift_expanded.index)\n",
    "        Yb_shift_interpolated = pd.Series(Yb_smoothed_level, index=Yb_shift_expanded.index)\n",
    "\n",
    "        Al_long_gap_mask = detect_long_missing(Al_shift_expanded, max_len=interp_limit)\n",
    "        Al_shift_interpolated[Al_long_gap_mask] = np.nan\n",
    "        Al_shift_final = Al_shift_interpolated[comb_datetime.index]\n",
    "        Al_key_name = f\"Al_shift_final_{my_method}\"\n",
    "        interp_Al_results[Al_key_name] = Al_shift_final.copy()\n",
    "        interp_Al_results[Al_key_name].name = Al_key_name\n",
    "\n",
    "        Sr_long_gap_mask = detect_long_missing(Sr_shift_expanded, max_len=interp_limit)\n",
    "        Sr_shift_interpolated[Sr_long_gap_mask] = np.nan\n",
    "        Sr_shift_final = Sr_shift_interpolated[comb_datetime.index]\n",
    "        Sr_key_name = f\"Sr_shift_final_{my_method}\"\n",
    "        interp_Sr_results[Sr_key_name] = Sr_shift_final.copy()\n",
    "        interp_Sr_results[Sr_key_name].name = Sr_key_name\n",
    "\n",
    "        Yb_long_gap_mask = detect_long_missing(Yb_shift_expanded, max_len=interp_limit)\n",
    "        Yb_shift_interpolated[Yb_long_gap_mask] = np.nan\n",
    "        Yb_shift_final = Yb_shift_interpolated[comb_datetime.index]\n",
    "        Yb_key_name = f\"Yb_shift_final_{my_method}\"\n",
    "        interp_Yb_results[Yb_key_name] = Yb_shift_final.copy()\n",
    "        interp_Yb_results[Yb_key_name].name = Yb_key_name\n",
    "    else: \n",
    "        # general interpolation \n",
    "        Al_shift_interpolated = Al_shift_expanded.interpolate(method=my_method, limit=interp_limit)\n",
    "        Al_shift_final = Al_shift_interpolated[comb_datetime.index]\n",
    "        Al_key_name = f\"Al_shift_final_{my_method}\"\n",
    "        interp_Al_results[Al_key_name] = Al_shift_final.copy()\n",
    "        interp_Al_results[Al_key_name].name = Al_key_name\n",
    "\n",
    "        Sr_shift_interpolated = Sr_shift_expanded.interpolate(method=my_method, limit=interp_limit)\n",
    "        Sr_shift_final = Sr_shift_interpolated[comb_datetime.index]\n",
    "        Sr_key_name = f\"Sr_shift_final_{my_method}\"\n",
    "        interp_Sr_results[Sr_key_name] = Sr_shift_final.copy()\n",
    "        interp_Sr_results[Sr_key_name].name = Sr_key_name\n",
    "\n",
    "        Yb_shift_interpolated = Yb_shift_expanded.interpolate(method=my_method, limit=interp_limit)\n",
    "        Yb_shift_final = Yb_shift_interpolated[comb_datetime.index]\n",
    "        Yb_key_name = f\"Yb_shift_final_{my_method}\"\n",
    "        interp_Yb_results[Yb_key_name] = Yb_shift_final.copy()\n",
    "        interp_Yb_results[Yb_key_name].name = Yb_key_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec91de7",
   "metadata": {},
   "source": [
    "## Analyze results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96ef11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date:  20250116  Method:  kalman \n",
      "\n",
      "Al+/Sr ratio offset from BACON paper -1.3570E-16\n",
      "Yb/Sr ratio offset from BACON paper -1.0030E-16\n",
      "Al+/Yb ratio offset from BACON paper -3.4786E-17 \n",
      "\n",
      "Al+/Sr ADEV with tau= 1130 :  4.3210E-18\n",
      "Yb/Sr ADEV with tau= 1130 :  4.3210E-18\n",
      "Al+/Yb ADEV with tau= 1178 :  6.1869E-18\n"
     ]
    }
   ],
   "source": [
    "##specify which interpolation results to view of ['time', 'linear', 'pad', 'nearest', 'cubic', 'kalman'] \n",
    "method_res = \"kalman\" \n",
    "\n",
    "\n",
    "if method_res == \"kalman\":\n",
    "    starting_index = 30\n",
    "else:\n",
    "    starting_index = 0\n",
    "    \n",
    "## process results for analysis \n",
    "nuAl = [Decimal(i) for i in comb['nuAl']]\n",
    "nuSr = [Decimal(i) for i in comb['nuSr']]\n",
    "nuYb = [Decimal(i) for i in comb['nuYb']]\n",
    "\n",
    "shiftAl = [Decimal(i) for i in interp_Al_results[f\"Al_shift_final_{method_res}\"]]\n",
    "shiftSr = [Decimal(i) for i in interp_Sr_results[f\"Sr_shift_final_{method_res}\"]]\n",
    "shiftYb = [Decimal(i) for i in interp_Yb_results[f\"Yb_shift_final_{method_res}\"]]\n",
    "\n",
    "frequency_Al_ErYb = [((i + j) * total_correction_Al).iloc[0] for i, j in zip(nuAl[starting_index:], shiftAl[starting_index:])]\n",
    "frequency_Sr_ErYb = [((i + j) * total_correction_Sr).iloc[0] for i, j in zip(nuSr[starting_index:], shiftSr[starting_index:])]\n",
    "frequency_Yb_ErYb = [((i + j) * total_correction_Yb).iloc[0] for i, j in zip(nuYb[starting_index:], shiftYb[starting_index:])]\n",
    "\n",
    "frequency_ratio_ErYb1 = [(i / j - AlSrRatio2020)/AlSrRatio2020 for i,j in zip(frequency_Al_ErYb, frequency_Sr_ErYb)]\n",
    "frequency_ratio_ErYb2 = [(i / j - YbSrRatio2020)/YbSrRatio2020 for i,j in zip(frequency_Yb_ErYb, frequency_Sr_ErYb)]\n",
    "frequency_ratio_ErYb3 = [(i / j - AlYbRatio2020)/AlYbRatio2020 for i,j in zip(frequency_Al_ErYb, frequency_Yb_ErYb)]\n",
    "\n",
    "clean_frequency_ratio_ErYb1 = clean_frequency_ratio(frequency_ratio_ErYb1)\n",
    "clean_frequency_ratio_ErYb2 = clean_frequency_ratio(frequency_ratio_ErYb2)\n",
    "clean_frequency_ratio_ErYb3 = clean_frequency_ratio(frequency_ratio_ErYb3)\n",
    "\n",
    "## print summary statistics \n",
    "if day_irregular_index != None:\n",
    "    print(\"Date: \", days_irregular[day_irregular_index], \" Method: \", method_res, \"\\n\")\n",
    "else: \n",
    "    print(\"Date: \", days[day_index], \" Method: \", method_res, \"\\n\")\n",
    "print(\"Al+/Sr ratio offset from BACON paper\", '{:0.5}'.format(np.nanmean(frequency_ratio_ErYb1)))\n",
    "print(\"Yb/Sr ratio offset from BACON paper\", '{:0.5}'.format(np.nanmean(frequency_ratio_ErYb2)))\n",
    "print(\"Al+/Yb ratio offset from BACON paper\", '{:0.5}'.format(np.nanmean(frequency_ratio_ErYb3)), '\\n')\n",
    "\n",
    "print(\"Al+/Sr ADEV with tau=\", math.floor(len(clean_frequency_ratio_ErYb1)/3), \": \", '{:0.5}'.format(overlapping_avar_fn(clean_frequency_ratio_ErYb1, math.floor(len(clean_frequency_ratio_ErYb1)/3)).sqrt()))\n",
    "print(\"Yb/Sr ADEV with tau=\", math.floor(len(clean_frequency_ratio_ErYb2)/3), \": \", '{:0.5}'.format(overlapping_avar_fn(clean_frequency_ratio_ErYb1, math.floor(len(clean_frequency_ratio_ErYb2)/3)).sqrt())) \n",
    "print(\"Al+/Yb ADEV with tau=\", math.floor(len(clean_frequency_ratio_ErYb3)/3), \": \", '{:0.5}'.format(overlapping_avar_fn(clean_frequency_ratio_ErYb3, math.floor(len(clean_frequency_ratio_ErYb1)/3)).sqrt()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
