---
title: "Clock data interpolation TN draft"
author: "Thornton"
output:
  word_document:
bibliography: References.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(MASS)
```


<!--- Open Command Palette: Press F1 or Ctrl + Shift + P to open the command palette.
Run Knit Command: Type rmarkdown: Render and select the desired output format (e.g., HTML, PDF).--->
# Introduction

The purpose of this report is to present a methodological approach for applying imputation and interpolation techniques to clock frequency data. This report is a result of collaborative research into statistical methods for the analysis of high-precision atomic clock data by the Statistical Engineering Division of the Information Technology Laboratory and the Time and Frequency Division of the Physical Measurement Laboratory. 

Because of the high precision in observed data, the reproducible estimation of, say, atomic clock frequency ratios requires careful attention to data processing steps. The idiosyncrasies of processing clock data that we focus on in this report options for the treatment of missing data and for the comparison of low frequency data to high frequency data. We describe the nature of these challenges with supporting examples and we present recommendations for addressing these challenges in a transparent, reproducible manner.      


## Audience

## Collaborators  

## Report Organization 
The next section presents some background information and an example to provide context for the problem at hand. Section 3 discusses the initial necessary data exploration steps, Section 4 covers interpolation methods for handling multiple, misaligned data sets, and Section 5 concludes by summarizing the steps needed to produce a coherent final data set for estimation and inference. 


<!-------------------------------------------------------------->
# Background 

The challenge presented here has several layers that complicate a traditional time series analysis. Although the ultimate analysis is of a single time series, let's call this the target series, the target series is computed based on calculations involving at least three individual time series, we will call these sub-series. Each sub-series is independent of the others but each may contain missing values and is irregularly sampled. Furthermore, the sub-series may have slightly or dramatically different start and end times. 

The application that motivates this article is the analysis of atomic clock ratio data. 

[Background on existing approaches for combining time series i.e. convolution of time series]

[Background on existing methods for univariate time series imputation] @howe2021, @pavia2010, @lepot2017

[Background on existing work mapping low frequency series to high frequency one. AKA mixed frequency data analysis] 

[Background on existing work on irregularly samples time series.] @shukla2019 @nieto2015 @erdogan2005

[Mention and reference work on spectral analysis of time series for atomic clock data] In this article, we restrict our focus to analysis in the time domain. In the example application of atomic clock ratio data, the results of interest include estimates of the mean and Allan deviation of the target series. 

<!-------------------------------------------------------------->
# Data Exploration

## Visualize Missing Data 

Data visualization is an important first step to identify any missing data or unexpected patterns. It is crucial that individual time series are visualized before they are combined. This step also helps with the determination of identifying the overlapping window of observations which is the topic of the next section. 

To understand the magnitude of any missing data issues, one can count the missing observations in each time series. For example, the following Python code reports the total number of missing data points (i.e. truly empty data values). 

```{python, eval=FALSE, echo=TRUE}
missing_index = pd.isnull(time_series_data)
print(missing_index.sum())
```

While this numerical summary of missing values is informative, it is not enough to identify any unusual patterns in missing data. There is no substitute for a visual analysis of data. A useful Python package for visualizing any patterns in missing data is the package "missingno" which can be implemented as follows. 

```{python, eval=FALSE, echo=TRUE}
import missingno as msno

msno.matrix(time_series_data)
plt.show()
```

The treatment of long sequences of missing data is distinct from the treatment of individual missing data points. While common imputation techniques for univariate time series [cite sources] can be implemented for individual missing values, long sequences of missingness indicate a need to reconsider the start and end times of the series. Large gaps of missing data must be factored in to the next step where one decides which window of observations to analyze. This is the topic of the next section.   

[Add note of caution about how keeping missing data until end is not advisable.] 

## Determine Overlapping Window of Observation 

An important characteristic of clock and comb data is that the beginning and end point of observations may vary among each data file under consideration. If there are any large gaps of missing data in the clock shift files, this should also be taken into consideration when determining the start and end time points of the data. Therefore, a necessary component to preparing the data for analysis is first identifying the overlapping windows of observation for each time series. The goal of this step is to find a time interval $[t_{MJD,i}, t_{MDJ, j}]$ that includes the largest possible intersection of observations from each data file. 

Let $X = 60535$ and consider, for example, a time series of comb data that begins at $t_{MJD} = X + 0.682346$ and ends at $t_{MJD} = X + 0.911951$. Suppose we are interested in estimating the average frequency ratio of the $Al+$ and $Sr$ clocks which begin and end at $[X + 0.6818403, X + 0.9108218]$ and $[X + 0.705143550906, X + 0.9791847021]$, respectively. For now, suppose there are no gaps of missing data in either clock time series. 


```{r, echo=FALSE}
library(ggplot2) 
x <- 60535
comb <- c(x + 0.71, x + 0.92)
al <- c(x + 0.6818403, x + 0.9108218 )
sr <- c(x + 0.705143550906, x + 0.9791847021)
df <- data.frame(c("Clock 1", "Clock 2", "Comb"), rbind(al, sr, comb))
colnames(df) <- c("Series", "start", "end")
rownames(df) <- NULL
df_plot <- data.frame(Series = rep(df$Series,2), time = c(df$start, df$end)) 

ggplot(df_plot) +
  geom_point(aes(x=time, y=0, color=Series), size = 15, shape="|", alpha=0.7)  +
  annotate("segment", x=min(df$start)-0.01, xend=max(df$end)+0.01, y=0, yend=0, linewidth=1) +
#  annotate("segment", x=min(df$start)-0.01, xend=min(df$start)-0.01, y=-0.0001, yend=0.0001, linewidth=2) +
#  annotate("segment", x=max(df$end)+0.01, xend=max(df$end)+0.01, y=-0.0001, yend=0.0001, linewidth=2) +
#  geom_text(aes(label = x), col="white") +
  scale_x_continuous(limits = c(min(df$start)-0.01, max(df$end)+0.01)) +
  scale_y_continuous(limits = c(-0.001,0.001)) +
#  scale_color_manual(values = unname(colours)) + 
  theme(panel.background = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank())
```

The follow Python functions are useful in determining the final intersecting time interval for analysis. 

```{python, eval=FALSE, echo=TRUE}
# Extracts series element that is as close to the target as possible without going over.
def lb_extract(target, data):
    inx = 0
    stopper = 1
    while stopper == 1:
        if data[inx] <= target:
            inx += 1
        else:
            return inx  

# Extracts series element that is as close to target as possible without going under.  
def ub_extract(target, data):
    inx = 1
    stopper = 1
    while stopper == 1:
        if data[len(data)-inx] >= target:
            inx += 1
        else:
            return len(data)-inx 
```


<!-------------------------------------------------------------->
# Interpolation 


## Frequency Alignment

The culmination of the previous data processing steps is the arithmetic combination of several time series that are observed with different frequencies. At this stage, there is no missing data in any of the series; however, each series is comprised of observations along an irregular time scale. [For scientific reasons], the comb time series is typically observed more regularly than any individual clock shift series. Thus the comb data represent a high-frequency series and the clock shift data are low-frequency in comparison. 

To derive a ratio time series for any two clocks, the time points of observations for each clock must be in alignment with those of the comb. There are several methodological approaches one may take to align all three series. Without loss of generality, suppose clock A is observed with either the same or a lower frequency compared to clock B and suppose that clock B and the comb data are observed with similar frequencies. 

**Method 1**: Align clock A with the observations of the comb. Then align clock B with the observations of the comb. Proceed to derive the ratio time series for analysis. The result of this approach will be a time series with the same irregularities in sampling as the comb series.  

**Method 2**: Align clock A with the observations of clock B. Then align the new series for clock A with the comb. Finally, align clock B with the comb and proceed to derive the ratio time series for analysis. This approach may be reasonable if clock A is observed with a much lower frequency compared to clock B. As with Method 1, the result will be a time series with the same irregular observation pattern as the comb data.  

**Method 3**: Realign the comb time series so that the observations are regularly sampled along the time interval of interest. Align clock A with the new, regularly observed comb series. Align clock B with the new, regularly observed comb series. Proceed to derive the ratio time series for analysis. The result of this approach will be a regularly sampled time series.  

**Method 4**: Align clock A with the observations of clock B. Then align the comb with clock B. Proceed to derive the ratio time series for analysis. The result of this approach will be a time series with the same irregularities in sampling as the series of observations from clock B. This approach essentially disregards or masks comb data for the sake of matching the observational time points of clock B. 

**Method 5**: Realign the time series from clock B so that the observations are regularly sampled along the time interval of interest. Align clock A with the new, regularly observed series from clock B. Align the comb with the new, regularly observed series from clock B. Proceed to derive the ratio time series for analysis. The result of this approach will be a regularly sampled time series. 

Note that none of the methods listed above suggest realigning a high frequency series to match a low frequency series. This is because such an approach would sacrifice valuable information contained in the higher frequency series and is generally not advisable. Although it is listed above for the sake of completeness, Method 2 is inferior to the other methods because it results in an irregularly sampled time series and it requires three separate interpolation steps. In comparison, Methods 1 and 2 only require two separate interpolation steps. The drawback of these two methods however is that the resulting time series is still irregularly observed. Methods 3 and 5 on the other hand, each require three separate interpolation steps, but the result is a regularly sampled time series. 

Depending on the type of analysis, having an irregularly sampled time series may or may not be of concern. For example, if the analysis is based upon a multitaper spectral approach such as that in [cite clock paper], then the sampling irregularities do not present an issue. [cite sources as to why not]. However, if the analysis is to proceed in [the time domain?], irregularities in the observational frequency of the time series will bias common estimates of interest such as the mean and AVAR. [cite sources] 

## Interpolation techniques 



Once a method for alignment is determined, the implementation of the alignment will occur through time series interpolation. There are many different techniques for interpolating time series data. [Cite some sources.]  

<!-------------------------------------------------------------->
# Conclusion 

The process we have outlined for aligning the observational frequency of clock time series follows these steps: 

Step 1) Process the data for each time series to determine the final window of observation and exclude low-quality data. 

Step 2) Determine if there are any missing data and decide whether or not to impute values that are missing. 

Step 3) Determine which method of frequency alignment will be used and decide upon an interpolation technique to implement the alignment. 

Calculate clock frequencies by adding together comb frequencies and shift data, scaled by the total correction amount 

[all of this analysis is occurring within the time domain? not the frequency domain?] 



