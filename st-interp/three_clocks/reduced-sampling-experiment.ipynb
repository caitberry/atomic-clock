{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#############  Purpose                     #####################################\n",
    "## This code compares mean and variance estimates for Al+ time series \n",
    "## (not ratio) for high and low frequency of observations. The low frequency \n",
    "## is set to match the sampling rate of Sr. \n",
    "## The point is to see if the difference in sampling rates of the two clocks\n",
    "## has any impact on the estimates of interest. \n",
    "################################################################################\n",
    "\n",
    "import pandas as pd\n",
    "from decimal import Decimal\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "################################################################################\n",
    "#############  Functions for data loading #####################################\n",
    "################################################################################\n",
    "\n",
    "## comb data \n",
    "def open_ErYb_data(data_path, header=2):\n",
    "    # keys to read out as string\n",
    "    key2read = [\"MJD\", \"timer\", \"SDR:frep_ErYb\", \"fo_ErYb\", \"fb_Si_ErYb\", \"fb_Al_ErYb\", \"fb_Yb_ErYb\"] \n",
    "    types = {key: str for key in key2read}\n",
    "    types[\"MJD\"] = float\n",
    " \n",
    "    # # Read the CSV file\n",
    "    data = pd.read_csv(data_path, header=1, delimiter=\"\\t\", dtype=types, engine=\"python\")\n",
    " \n",
    "    # Convert the strings to Decimal for the given keys\n",
    "    for k in key2read:\n",
    "        data[k] = data[k].apply(Decimal)\n",
    " \n",
    "    # reindex data\n",
    "    data.index = range(len(data))\n",
    " \n",
    "    return data[list(types.keys())]\n",
    "\n",
    "## Al shift data \n",
    "def open_shiftfile_Al(datapath):\n",
    "    data = pd.read_csv(datapath, header=30, delimiter=\"\\t\", dtype={1: str}, engine=\"python\")\n",
    " \n",
    "    # Replace column names\n",
    "    data.columns = [\"MJD\", \"shift\", \"IS_GOOD\"]\n",
    " \n",
    "    # Change column type from float to bool\n",
    "    data[\"IS_GOOD\"] = data[\"IS_GOOD\"].apply(lambda x: x == 1.0)\n",
    " \n",
    "    # Put NaN in data[\"shift\"] where data[\"IS_GOOD\"] is 0\n",
    "    data.loc[~data[\"IS_GOOD\"], \"shift\"] = np.nan\n",
    " \n",
    "    # Change column type to float\n",
    "    data[\"shift\"] = data[\"shift\"].apply(float)\n",
    " \n",
    "    return data\n",
    " \n",
    " ## Yb shift data\n",
    "def open_shiftfile_Yb(datapath):\n",
    "    data = pd.read_csv(datapath, header=8, delimiter=r\"\\t\", dtype={1: str}, engine=\"python\")\n",
    " \n",
    "    # Replace column names\n",
    "    data.columns = [\"MJD\", \"shift\", \"IS_GOOD\"]\n",
    " \n",
    "    # Change column type from float to bool\n",
    "    data[\"IS_GOOD\"] = data[\"IS_GOOD\"].apply(lambda x: x == 1.0)\n",
    " \n",
    "    # Put NaN in data[\"shift\"] where data[\"IS_GOOD\"] is 0\n",
    "    data.loc[~data[\"IS_GOOD\"], \"shift\"] = np.nan\n",
    " \n",
    "    # Change column type to float\n",
    "    data[\"shift\"] = data[\"shift\"].apply(float)\n",
    " \n",
    "    return data\n",
    " \n",
    " \n",
    " \n",
    "################################################################################\n",
    "#############  Functions to find optical frequencies with comb equation ########\n",
    "################################################################################\n",
    " \n",
    "# frequency for Al+ clock\n",
    "def compute_nuAl_ErYb(data):\n",
    "    data[\"nuAl\"] = -Decimal(\"105e6\") + Decimal(\"560444\") * (Decimal(\"1e9\") + data[\"SDR:frep_ErYb\"]) / Decimal(2) - data[\"fb_Al_ErYb\"]\n",
    "    data[\"nuAl\"] = Decimal(4) * data[\"nuAl\"]   \n",
    "\n",
    "# freuency for Yb clock\n",
    "def compute_nuYb_ErYb(data):\n",
    "    data[\"nuYb\"] = -Decimal(\"105e6\") + Decimal(\"518237\") * (Decimal(\"1e9\") + data[\"SDR:frep_ErYb\"]) / Decimal(2) - data[\"fb_Yb_ErYb\"]\n",
    "    data[\"nuYb\"] = Decimal(2) * data[\"nuYb\"]\n",
    "\n",
    " \n",
    "################################################################################\n",
    "#############################  Load data #######################################\n",
    "################################################################################\n",
    " \n",
    "path = \"/Users/smt3/Documents/GitHub/atomic-clock/st-interp/three_clocks/\"\n",
    "\n",
    "# load comb data\n",
    "data_ErYb = open_ErYb_data(path + \"20240813_Deglitched_ErYb_only1.dat\")\n",
    " \n",
    "# load Al shift data \n",
    "shift_data_Al = open_shiftfile_Al(path + \"20240813_Al+_Freq_Shifts_ErYb.dat\")\n",
    "\n",
    "# load Yb shift data\n",
    "shift_data_Yb = open_shiftfile_Yb(path + \"20240813_Yb_Freq_Shifts.txt\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "Total NaNs: 29\n",
      "Longest sequence of NaNs: 5\n"
     ]
    }
   ],
   "source": [
    " \n",
    "################################################################################\n",
    "###############  get optical frequencies #############################\n",
    "################################################################################\n",
    " \n",
    "compute_nuAl_ErYb(data_ErYb)\n",
    "compute_nuYb_ErYb(data_ErYb) \n",
    " \n",
    "\n",
    "################################################################################\n",
    "#########################  Data Processing #####################################\n",
    "################################################################################\n",
    "\n",
    "## Extract only \"IS_GOOD\" data for analysis \n",
    "good_condition_al = shift_data_Al[\"IS_GOOD\"] == 1\n",
    "shift_data_Al_good = shift_data_Al[good_condition_al].reset_index(drop=True)\n",
    "good_condition_yb = shift_data_Yb[\"IS_GOOD\"] == 1\n",
    "shift_data_Yb_good = shift_data_Yb[good_condition_yb].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# ## View frequency of MDJ observations  \n",
    "# shift_data_Al[\"MJD_diff\"] = shift_data_Al.MJD.diff()\n",
    "\n",
    "# series_MJD_Al_diff = shift_data_Al[\"MJD_diff\"]\n",
    "# # plt.hist(series_MJD_Sr_diff.dropna(), bins = 500)\n",
    "# # plt.xlim(0.00005, 0.00025)\n",
    "# # plt.show()\n",
    "\n",
    "# #print(series_MJD_Sr_diff.dtype)\n",
    "# series_MJD_Al_diff.describe()\n",
    "\n",
    "#mode MJD diff for Sr: 0.0001, max diff: 0.001224\n",
    "#mode MJD diff for Al: 0.000012, max diff: 0.018264\n",
    "\n",
    "common_mjd = data_ErYb[\"MJD\"].astype(float)\n",
    "nuAl = data_ErYb[\"nuAl\"].astype(float)\n",
    "nuYb = data_ErYb['nuYb'].astype(float)\n",
    "\n",
    "print(\"Missing Al comb nu: \", nuAl.isna().sum())\n",
    "print(\"Missing Yb comb nu: \", nuYb.isna().sum())\n",
    "\n",
    "#is_na = nuAl.isna()\n",
    "is_na = nuYb.isna()\n",
    "max_streak = current_streak = 0\n",
    "for val in is_na:\n",
    "    if val:\n",
    "        current_streak += 1\n",
    "        max_streak = max(max_streak, current_streak)\n",
    "    else:\n",
    "        current_streak = 0\n",
    "print(\"Total NaNs:\", is_na.sum())\n",
    "print(\"Longest sequence of NaNs:\", max_streak)\n",
    "\n",
    "# import missingno as msno\n",
    "# df = nuAl.to_frame()\n",
    "# msno.matrix(df)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## TODO: redo index analysis to include Yb observations as well \n",
    "\n",
    "#function to extract element as close to target as possible w/out going over\n",
    "def lb_extract(target, data):\n",
    "    inx = 0\n",
    "    stopper = 1\n",
    "    while stopper == 1:\n",
    "        if data[inx] <= target:\n",
    "            inx += 1\n",
    "        else:\n",
    "            return inx  \n",
    "\n",
    "#function to extract element as close to target as possible w/out going under \n",
    "def ub_extract(target, data):\n",
    "    inx = 1\n",
    "    stopper = 1\n",
    "    while stopper == 1:\n",
    "        if data[len(data)-inx] >= target:\n",
    "            inx += 1\n",
    "        else:\n",
    "            return len(data)-inx  \n",
    "\n",
    "#### first comb time point:  60535.682346  (# first good Al time point:  60535.6818403)\n",
    "#### last good Al time point:  60535.9108218  (# last comb time point:  60535.911951)\n",
    "\n",
    "len_comb = len(common_mjd) \n",
    "len_Al = len(shift_data_Al_good['MJD'])                  \n",
    "\n",
    "comb = pd.DataFrame()\n",
    "comb_end = lb_extract(target = shift_data_Al_good[\"MJD\"][len_Al-1], data = common_mjd)  \n",
    "comb[\"MJD\"] = common_mjd[1:comb_end] #b/c first entry of nuAl is NaN \n",
    "comb[\"nuAl\"] = nuAl[1:comb_end]\n",
    "comb['nuAl'] = pd.to_numeric(comb['nuAl'], errors='coerce')\n",
    "\n",
    "al_start = ub_extract(target = common_mjd[0], data = shift_data_Al_good[\"MJD\"])\n",
    "shift_data_Al_high = shift_data_Al_good[al_start:]\n",
    "\n",
    "yb_start = ub_extract(target = common_mjd[0], data = shift_data_Al_good[\"MJD\"])\n",
    "shift_data_Yb = shift_data_Yb_good[yb_start:]\n",
    "\n",
    "## reset df indicies for next step \n",
    "comb = comb.reset_index(drop=True)  \n",
    "shift_data_Al_high = shift_data_Al_high.reset_index(drop=True)\n",
    "shift_data_Yb = shift_data_Yb.reset_index(drop=True)\n",
    "\n",
    "#shift_data_Al_high[\"MJD\"].astype(float)\n",
    "#shift_data_Al_high[\"shift\"].astype(float)\n",
    "\n",
    "#print(comb_high.head)\n",
    "#print(shift_data_Al_high.head)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n",
      "18165\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def sample_indices(df: pd.DataFrame, freq: int) -> pd.Index: #type annotation meaning the expected output is pandas object type Index \n",
    "    \"\"\"\n",
    "    Returns a sampled set of indices from the DataFrame at the specified frequency.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The DataFrame to sample from.\n",
    "    - freq (int): The step size for sampling. For example, freq=2 will return every 2nd index.\n",
    "\n",
    "    Returns:\n",
    "    - pd.Index: A pandas Index containing the sampled indices.\n",
    "    \"\"\"\n",
    "    if freq <= 0:\n",
    "        raise ValueError(\"Frequency must be a positive integer.\")\n",
    "    \n",
    "    return df.index[::freq]\n",
    "\n",
    "inx_low = sample_indices(shift_data_Al_high[\"MJD\"], 9)\n",
    "shift_data_Al_low = shift_data_Al_high.loc[inx_low] \n",
    "\n",
    "print(len(shift_data_Al_low['MJD']))\n",
    "print(len(shift_data_Al_high['MJD']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18698\n",
      "18698\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "#########################  Interpolation             ###########################\n",
    "################################################################################\n",
    "# Interpolate missing nuAl values in comb df \n",
    "#print(comb['nuAl'].isna().sum())\n",
    "comb['nuAl'] = pd.to_numeric(comb['nuAl'], errors='coerce').interpolate(method='linear')\n",
    "comb['nuAl'] = [Decimal(i) for i in comb['nuAl']]\n",
    "comb['nuYb'] = pd.to_numeric(comb['nuYb'], errors='coerce').interpolate(method='linear')\n",
    "comb['nuYb'] = [Decimal(i) for i in comb['nuYb']]\n",
    "\n",
    "# Interpolate shift values to match comb grid \n",
    "shift_Al_low = np.interp(comb[\"MJD\"], shift_data_Al_low[\"MJD\"], shift_data_Al_low[\"shift\"])\n",
    "shift_Al_low = [Decimal(i) for i in shift_Al_low]\n",
    "shift_Al_high = np.interp(comb[\"MJD\"], shift_data_Al_high[\"MJD\"], shift_data_Al_high[\"shift\"])\n",
    "shift_Al_high = [Decimal(i) for i in shift_Al_high]\n",
    "shift_Yb = np.interp(comb[\"MJD\"], shift_data_Yb[\"MJD\"], shift_data_Yb[\"shift\"])\n",
    "shift_Yb = [Decimal(i) for i in shift_Yb]\n",
    "\n",
    "#note: lengths should match now b/c both interpolated onto comb['MJD'] grid \n",
    "print(len(shift_Al_low))\n",
    "print(len(shift_Al_high))\n",
    "\n",
    "shift_data_Al_low = pd.DataFrame(shift_Al_low, columns=['shift_interpolated'])\n",
    "shift_data_Al_high = pd.DataFrame(shift_Al_high, columns=['shift_interpolated'])\n",
    "shift_data_Yb = pd.DataFrame(shift_Yb, columns=['shift_interpolated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Al+ ave with lower sampling rate 1.1210E+15 \n",
      "\n",
      "18698\n",
      "Al+ ave with higher sampling rate 1.1210E+15 \n",
      "\n",
      "18698\n"
     ]
    }
   ],
   "source": [
    "AlYbRatio2020 = Decimal(\"2.162887127516663703\")\n",
    "\n",
    "# frequency corrections\n",
    "masercorrection = Decimal(\"-7.36631e-12\")\n",
    "GR_shift_Al = Decimal(\"-8.114e-16\")\n",
    "GR_shift_Yb = Decimal(\"-8.109e-16\")\n",
    "GR_shift_sea_level = Decimal(\"-1798.501e-16\")\n",
    "total_correction_Al = Decimal(\"1\") + GR_shift_Al + GR_shift_sea_level + masercorrection\n",
    "total_correction_Yb = Decimal(\"1\") + GR_shift_Yb + GR_shift_sea_level + masercorrection\n",
    "\n",
    "frequency_Yb_ErYb = [(i + j) * total_correction_Yb for i,j in zip(comb[\"nuYb\"], shift_data_Yb['shift_interpolated'])]\n",
    "frequency_Al_ErYb_low = [(i + j) * total_correction_Al for i,j in zip(comb['nuAl'], shift_data_Al_low['shift_interpolated'])]\n",
    "frequency_Al_ErYb_high = [(i + j) * total_correction_Al for i,j in zip(comb['nuAl'], shift_data_Al_high['shift_interpolated'])]\n",
    "#print(\"Al+ ave with lower sampling rate\", '{:0.5}'.format(np.nanmean(frequency_Al_ErYb_low)), '\\n' )\n",
    "#print(\"Al+ ave with higher sampling rate\", '{:0.5}'.format(np.nanmean(frequency_Al_ErYb_high)), '\\n' )\n",
    "\n",
    "\n",
    "# Al/Yb ratio offset with low sampling rate for Al \n",
    "frequency_ratio_ErYb1 = [(i / j - AlYbRatio2020)/AlYbRatio2020 for i,j in zip(frequency_Al_ErYb_low, frequency_Yb_ErYb)]\n",
    "print(\"Al/Yb ratio offset from BACON paper (Method 1)\", '{:0.5}'.format(np.nanmean(frequency_ratio_ErYb1)) )\n",
    "plt.figure()\n",
    "plt.plot(comb[\"MJD\"], frequency_ratio_ErYb1, '.')\n",
    "plt.grid(visible=True, which='major', color='#666666', linestyle='-')\n",
    "plt.minorticks_on()\n",
    "plt.grid(visible=True, which='minor', color='#999999', linestyle='-', alpha=0.2)\n",
    "plt.xlabel(\"MJD\")\n",
    "plt.ylabel(\"offset from Al/Yb ratio BACON ratio\")\n",
    "plt.title(\"Al/Yb ratio from 8/13/24 on common MJD grid\")\n",
    "plt.show()\n",
    "\n",
    "# Al/Yb ratio offset with high sampling rate for Al \n",
    "frequency_ratio_ErYb2 = [(i / j - AlYbRatio2020)/AlYbRatio2020 for i,j in zip(frequency_Al_ErYb_high, frequency_Yb_ErYb)]\n",
    "print(\"Al/Yb ratio offset from BACON paper (Method 1)\", '{:0.5}'.format(np.nanmean(frequency_ratio_ErYb2)) )\n",
    "plt.figure()\n",
    "plt.plot(comb[\"MJD\"], frequency_ratio_ErYb2, '.')\n",
    "plt.grid(visible=True, which='major', color='#666666', linestyle='-')\n",
    "plt.minorticks_on()\n",
    "plt.grid(visible=True, which='minor', color='#999999', linestyle='-', alpha=0.2)\n",
    "plt.xlabel(\"MJD\")\n",
    "plt.ylabel(\"offset from Al/Yb ratio BACON ratio\")\n",
    "plt.title(\"Al/Yb ratio from 8/13/24 on common MJD grid\")\n",
    "plt.show()\n",
    "\n",
    "## TODO\n",
    "# Al/Yb ratio difference? <-- redo index analysis to include Yb observations as well \n",
    "# review original data analysis w/ attention to comb missing data \n",
    "# allentools package how to calculate allan variance OR see code in functions.R (overlapping_avar_fn)\n",
    "#     aval plot (tau vs avar) and stability point estimate (extrapolated to whole data set, tau = length of time series) \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
