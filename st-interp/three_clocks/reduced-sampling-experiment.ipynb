{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#############  Purpose                     #####################################\n",
    "## This code compares mean and variance estimates for Al+ time series \n",
    "## (not ratio) for high and low frequency of observations. The low frequency \n",
    "## is set to match the sampling rate of Sr. \n",
    "## The point is to see if the difference in sampling rates of the two clocks\n",
    "## has any impact on the estimates of interest. \n",
    "################################################################################\n",
    "\n",
    "import pandas as pd\n",
    "from decimal import Decimal\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "################################################################################\n",
    "#############  Functions for data loading #####################################\n",
    "################################################################################\n",
    "\n",
    "## comb data \n",
    "def open_ErYb_data(data_path, header=2):\n",
    "    # keys to read out as string\n",
    "    key2read = [\"MJD\", \"timer\", \"SDR:frep_ErYb\", \"fo_ErYb\", \"fb_Si_ErYb\", \"fb_Al_ErYb\", \"fb_Yb_ErYb\"] \n",
    "    types = {key: str for key in key2read}\n",
    "    types[\"MJD\"] = float\n",
    " \n",
    "    # # Read the CSV file\n",
    "    data = pd.read_csv(data_path, header=1, delimiter=\"\\t\", dtype=types, engine=\"python\")\n",
    " \n",
    "    # Convert the strings to Decimal for the given keys\n",
    "    for k in key2read:\n",
    "        data[k] = data[k].apply(Decimal)\n",
    " \n",
    "    # reindex data\n",
    "    data.index = range(len(data))\n",
    " \n",
    "    return data[list(types.keys())]\n",
    "\n",
    "## Al shift data \n",
    "def open_shiftfile_Al(datapath):\n",
    "    data = pd.read_csv(datapath, header=30, delimiter=\"\\t\", dtype={1: str}, engine=\"python\")\n",
    " \n",
    "    # Replace column names\n",
    "    data.columns = [\"MJD\", \"shift\", \"IS_GOOD\"]\n",
    " \n",
    "    # Change column type from float to bool\n",
    "    data[\"IS_GOOD\"] = data[\"IS_GOOD\"].apply(lambda x: x == 1.0)\n",
    " \n",
    "    # Put NaN in data[\"shift\"] where data[\"IS_GOOD\"] is 0\n",
    "    data.loc[~data[\"IS_GOOD\"], \"shift\"] = np.nan\n",
    " \n",
    "    # Change column type to float\n",
    "    data[\"shift\"] = data[\"shift\"].apply(float)\n",
    " \n",
    "    return data\n",
    " \n",
    "## Sr shift data \n",
    "def open_shiftfile_Sr(datapath):\n",
    "    data = pd.read_csv(datapath, header=22, delimiter=\"\\t\", dtype={1: str}, engine=\"python\")\n",
    " \n",
    "    # Replace column names\n",
    "    data.columns = [\"MJD\", \"shift\", \"IS_GOOD\"]\n",
    " \n",
    "    # Change column type from float to bool\n",
    "    data[\"IS_GOOD\"] = data[\"IS_GOOD\"].apply(lambda x: x == 1.0)\n",
    " \n",
    "    # Put NaN in data[\"shift\"] where data[\"IS_GOOD\"] is 0\n",
    "    data.loc[~data[\"IS_GOOD\"], \"shift\"] = np.nan\n",
    " \n",
    "    # Change column type to float\n",
    "    data[\"shift\"] = data[\"shift\"].apply(float)\n",
    " \n",
    "    return data\n",
    " \n",
    " \n",
    "################################################################################\n",
    "#############  Functions to find optical frequencies with comb equation ########\n",
    "################################################################################\n",
    " \n",
    "# frequency for Al+ clock\n",
    "def compute_nuAl_ErYb(data):\n",
    "    data[\"nuAl\"] = -Decimal(\"105e6\") + Decimal(\"560444\") * (Decimal(\"1e9\") + data[\"SDR:frep_ErYb\"]) / Decimal(2) - data[\"fb_Al_ErYb\"]\n",
    "    data[\"nuAl\"] = Decimal(4) * data[\"nuAl\"]   \n",
    "\n",
    "# frequency for Sr clock \n",
    "def compute_nuSr_ErYb(data):\n",
    "    data[\"nuSi\"] = -Decimal(\"105e6\") + Decimal(\"388752\") * (Decimal(\"1e9\") + data[\"SDR:frep_ErYb\"]) / Decimal(2) - Decimal(\"100e6\")\n",
    "    data[\"nuSr\"] = (Decimal(\"1716882\") / Decimal(\"777577\")) * (data[\"nuSi\"] - Decimal(\"216e6\"))\n",
    "\n",
    "\n",
    " \n",
    "################################################################################\n",
    "#############################  Load data #######################################\n",
    "################################################################################\n",
    " \n",
    "path = \"/Users/smt3/Documents/GitHub/atomic-clock/st-interp/three_clocks/\"\n",
    "\n",
    "# load comb data\n",
    "data_ErYb = open_ErYb_data(path + \"20240813_Deglitched_ErYb_only1.dat\")\n",
    " \n",
    "# load Al shift data \n",
    "shift_data_Al = open_shiftfile_Al(path + \"20240813_Al+_Freq_Shifts_ErYb.dat\")\n",
    "\n",
    "# load Sr shift data\n",
    "shift_data_Sr = open_shiftfile_Sr(path + \"20240813_Sr_Freq_Shifts.dat\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "################################################################################\n",
    "###############  get optical frequencies #############################\n",
    "################################################################################\n",
    " \n",
    "compute_nuSr_ErYb(data_ErYb)\n",
    "compute_nuAl_ErYb(data_ErYb)\n",
    " \n",
    " \n",
    "\n",
    "################################################################################\n",
    "#########################  Data Processing #####################################\n",
    "################################################################################\n",
    "\n",
    "## Extract only \"IS_GOOD\" data for analysis \n",
    "good_condition_al = shift_data_Al[\"IS_GOOD\"] == 1\n",
    "shift_data_Al_good = shift_data_Al[good_condition_al].reset_index(drop=True)\n",
    "good_condition_sr = shift_data_Sr[\"IS_GOOD\"] == 1\n",
    "shift_data_Sr_good = shift_data_Sr[good_condition_sr].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# ## View frequency of MDJ observations  \n",
    "# shift_data_Al[\"MJD_diff\"] = shift_data_Al.MJD.diff()\n",
    "\n",
    "# series_MJD_Al_diff = shift_data_Al[\"MJD_diff\"]\n",
    "# # plt.hist(series_MJD_Sr_diff.dropna(), bins = 500)\n",
    "# # plt.xlim(0.00005, 0.00025)\n",
    "# # plt.show()\n",
    "\n",
    "# #print(series_MJD_Sr_diff.dtype)\n",
    "# series_MJD_Al_diff.describe()\n",
    "\n",
    "#mode MJD diff for Sr: 0.0001, max diff: 0.001224\n",
    "#mode MJD diff for Al: 0.000012, max diff: 0.018264\n",
    "\n",
    "common_mjd = data_ErYb[\"MJD\"].astype(float)\n",
    "nuAl = data_ErYb[\"nuAl\"].astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['MJD', 'shift', 'IS_GOOD'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Create low sampling frequency observations of Al and distinguish this from the high sampling case\n",
    "## Do the same for the relevant comb values \n",
    "\n",
    "#function to extract element as close to target as possible w/out going over\n",
    "def lb_extract(target, data):\n",
    "    inx = 0\n",
    "    stopper = 1\n",
    "    while stopper == 1:\n",
    "        if data[inx] <= target:\n",
    "            inx += 1\n",
    "        else:\n",
    "            return inx  \n",
    "\n",
    "#function to extract element as close to target as possible w/out going under \n",
    "def ub_extract(target, data):\n",
    "    inx = 1\n",
    "    stopper = 1\n",
    "    while stopper == 1:\n",
    "        if data[len(data)-inx] >= target:\n",
    "            inx += 1\n",
    "        else:\n",
    "            return len(data)-inx  \n",
    "\n",
    "#### first comb time point:  60535.682346  (# first good Al time point:  60535.6818403)\n",
    "#### last good Al time point:  60535.9108218  (# last comb time point:  60535.911951)\n",
    "\n",
    "len_comb = len(common_mjd) \n",
    "len_Al = len(shift_data_Al_good['MJD'])                  \n",
    "\n",
    "comb_high = pd.DataFrame()\n",
    "comb_end = lb_extract(target = shift_data_Al_good[\"MJD\"][len_Al-1], data = common_mjd)  \n",
    "comb_high[\"MJD\"] = common_mjd[1:comb_end] #b/c first entry of nuAl is NaN \n",
    "comb_high[\"nuAl\"] = nuAl[1:comb_end]\n",
    "comb_high['nuAl'] = pd.to_numeric(comb_high['nuAl'], errors='coerce')\n",
    "\n",
    "al_start = ub_extract(target = common_mjd[0], data = shift_data_Al_good[\"MJD\"])\n",
    "shift_data_Al_high = shift_data_Al_good[al_start:]\n",
    "\n",
    "print(shift_data_Al_high.columns)\n",
    "\n",
    "#shift_data_Al_high[\"MJD\"].astype(float)\n",
    "#shift_data_Al_high[\"shift\"].astype(float)\n",
    "\n",
    "#print(comb_high.head)\n",
    "#print(shift_data_Al_high.head)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#########################  Interpolation             ###########################\n",
    "## This step is necessary to do before sampling the indices \n",
    "## b/c MDJ comb and AL values do not match in value or frequency \n",
    "################################################################################\n",
    "# Interpolate missing nuAl values in comb df \n",
    "#print(comb_high['nuAl'].dtype)\n",
    "#print(comb_high['nuAl'].isna().sum())\n",
    "comb_high['nuAl'] = pd.to_numeric(comb_high['nuAl'], errors='coerce').interpolate(method='linear')\n",
    "\n",
    "\n",
    "# Interpolate shift values to match comb grid \n",
    "shift_Al_high = np.interp(comb_high[\"MJD\"], shift_data_Al_high[\"MJD\"], shift_data_Al_high[\"shift\"])\n",
    "shift_Al_high = [Decimal(i) for i in shift_Al_high]\n",
    "\n",
    "#print(shift_Al_high[:5])  #prints first few elements of a list \n",
    "\n",
    "shift_data_Al_high = pd.DataFrame(shift_Al_high, columns=['shift_interpolated'])\n",
    "\n",
    "## reset df indicies for next step \n",
    "comb_high = comb_high.reset_index(drop=True)  \n",
    "shift_data_Al_high = shift_data_Al_high.reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "float64\n",
      "<class 'pandas.core.series.Series'>\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def sample_indices(df: pd.DataFrame, freq: int) -> pd.Index: #type annotation meaning the expected output is pandas object type Index \n",
    "    \"\"\"\n",
    "    Returns a sampled set of indices from the DataFrame at the specified frequency.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The DataFrame to sample from.\n",
    "    - freq (int): The step size for sampling. For example, freq=2 will return every 2nd index.\n",
    "\n",
    "    Returns:\n",
    "    - pd.Index: A pandas Index containing the sampled indices.\n",
    "    \"\"\"\n",
    "    if freq <= 0:\n",
    "        raise ValueError(\"Frequency must be a positive integer.\")\n",
    "    \n",
    "    return df.index[::freq]\n",
    "\n",
    "inx_low = sample_indices(comb_high[\"MJD\"], 9)\n",
    "\n",
    "comb_low = comb_high.loc[inx_low]\n",
    "shift_data_Al_low = shift_data_Al_high.loc[inx_low] \n",
    "\n",
    "\n",
    "shift_data_Al_low['shift_interpolated'] = pd.to_numeric(shift_data_Al_low['shift_interpolated'], errors='coerce')\n",
    "shift_data_Al_high['shift_interpolated'] = pd.to_numeric(shift_data_Al_high['shift_interpolated'], errors='coerce')\n",
    "\n",
    "comb_low['nuAl'] = pd.to_numeric(comb_low['nuAl'], errors='coerce')\n",
    "comb_high['nuAl'] = pd.to_numeric(comb_high['nuAl'], errors='coerce')\n",
    "\n",
    "\n",
    "print(type(shift_data_Al_high['shift_interpolated']))\n",
    "print(shift_data_Al_high['shift_interpolated'].dtype)\n",
    "print(type(comb_high['nuAl']))\n",
    "print(comb_high['nuAl'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "object\n",
      "<class 'pandas.core.series.Series'>\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "#########################  Estimation                ###########################\n",
    "## TODO: calculate AVAR for each set also \n",
    "################################################################################\n",
    "# format data types \n",
    "comb_low['nuAl'] = [Decimal(i) for i in comb_low['nuAl']]\n",
    "comb_high['nuAl'] = [Decimal(i) for i in comb_high['nuAl']]\n",
    "#shift_data_Al_low['shift_interpolated'] = shift_data_Al_low['shift_interpolated'].apply(Decimal)\n",
    "#shift_data_Al_high['shift_interpolated'] = shift_data_Al_high['shift_interpolated'].apply(Decimal)\n",
    "shift_data_Al_low['shift_interpolated'] = [Decimal(i) for i in shift_data_Al_low['shift_interpolated']]\n",
    "shift_data_Al_high['shift_interpolated'] = [Decimal(i) for i in shift_data_Al_high['shift_interpolated']]\n",
    "\n",
    "\n",
    "print(type(shift_data_Al_high['shift_interpolated']))\n",
    "print(shift_data_Al_high['shift_interpolated'].dtype)\n",
    "print(type(comb_high['nuAl']))\n",
    "print(comb_high['nuAl'].dtype)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Al+ ave with lower sampling rate 1.1210E+15 \n",
      "\n",
      "Al+ ave with higher sampling rate 1.1210E+15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# frequency corrections\n",
    "masercorrection = Decimal(\"-7.36631e-12\")\n",
    "GR_shift_Al = Decimal(\"-8.114e-16\")\n",
    "GR_shift_sea_level = Decimal(\"-1798.501e-16\")\n",
    "total_correction_Al = Decimal(\"1\") + GR_shift_Al + GR_shift_sea_level + masercorrection\n",
    "\n",
    "frequency_Al_ErYb_low = [(i + j) * total_correction_Al for i,j in zip(comb_low['nuAl'], shift_data_Al_low['shift_interpolated'])]\n",
    "frequency_Al_ErYb_high = [(i + j) * total_correction_Al for i,j in zip(comb_high['nuAl'], shift_data_Al_high['shift_interpolated'])]\n",
    "print(\"Al+ ave with lower sampling rate\", '{:0.5}'.format(np.nanmean(frequency_Al_ErYb_low)), '\\n' )\n",
    "print(\"Al+ ave with higher sampling rate\", '{:0.5}'.format(np.nanmean(frequency_Al_ErYb_high)) )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
