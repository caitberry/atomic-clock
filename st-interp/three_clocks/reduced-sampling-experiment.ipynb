{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#############  Purpose                     #####################################\n",
    "## This code compares mean and variance estimates for Al+ time series \n",
    "## (not ratio) for high and low frequency of observations. The low frequency \n",
    "## is set to match the sampling rate of Sr. \n",
    "## The point is to see if the difference in sampling rates of the two clocks\n",
    "## has any impact on the estimates of interest. \n",
    "################################################################################\n",
    "\n",
    "import pandas as pd\n",
    "from decimal import Decimal\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "################################################################################\n",
    "#############  Functions for data loading #####################################\n",
    "################################################################################\n",
    "\n",
    "## comb data \n",
    "def open_ErYb_data(data_path, header=2):\n",
    "    # keys to read out as string\n",
    "    key2read = [\"MJD\", \"timer\", \"SDR:frep_ErYb\", \"fo_ErYb\", \"fb_Si_ErYb\", \"fb_Al_ErYb\", \"fb_Yb_ErYb\"] \n",
    "    types = {key: str for key in key2read}\n",
    "    types[\"MJD\"] = float\n",
    " \n",
    "    # # Read the CSV file\n",
    "    data = pd.read_csv(data_path, header=1, delimiter=\"\\t\", dtype=types, engine=\"python\")\n",
    " \n",
    "    # Convert the strings to Decimal for the given keys\n",
    "    for k in key2read:\n",
    "        data[k] = data[k].apply(Decimal)\n",
    " \n",
    "    # reindex data\n",
    "    data.index = range(len(data))\n",
    " \n",
    "    return data[list(types.keys())]\n",
    "\n",
    "## Al shift data \n",
    "def open_shiftfile_Al(datapath):\n",
    "    data = pd.read_csv(datapath, header=30, delimiter=\"\\t\", dtype={1: str}, engine=\"python\")\n",
    " \n",
    "    # Replace column names\n",
    "    data.columns = [\"MJD\", \"shift\", \"IS_GOOD\"]\n",
    " \n",
    "    # Change column type from float to bool\n",
    "    data[\"IS_GOOD\"] = data[\"IS_GOOD\"].apply(lambda x: x == 1.0)\n",
    " \n",
    "    # Put NaN in data[\"shift\"] where data[\"IS_GOOD\"] is 0\n",
    "    data.loc[~data[\"IS_GOOD\"], \"shift\"] = np.nan\n",
    " \n",
    "    # Change column type to float\n",
    "    data[\"shift\"] = data[\"shift\"].apply(float)\n",
    " \n",
    "    return data\n",
    " \n",
    "## Sr shift data \n",
    "def open_shiftfile_Sr(datapath):\n",
    "    data = pd.read_csv(datapath, header=22, delimiter=\"\\t\", dtype={1: str}, engine=\"python\")\n",
    " \n",
    "    # Replace column names\n",
    "    data.columns = [\"MJD\", \"shift\", \"IS_GOOD\"]\n",
    " \n",
    "    # Change column type from float to bool\n",
    "    data[\"IS_GOOD\"] = data[\"IS_GOOD\"].apply(lambda x: x == 1.0)\n",
    " \n",
    "    # Put NaN in data[\"shift\"] where data[\"IS_GOOD\"] is 0\n",
    "    data.loc[~data[\"IS_GOOD\"], \"shift\"] = np.nan\n",
    " \n",
    "    # Change column type to float\n",
    "    data[\"shift\"] = data[\"shift\"].apply(float)\n",
    " \n",
    "    return data\n",
    " \n",
    " \n",
    "################################################################################\n",
    "#############  Functions to find optical frequencies with comb equation ########\n",
    "################################################################################\n",
    " \n",
    "# frequency for Al+ clock\n",
    "def compute_nuAl_ErYb(data):\n",
    "    data[\"nuAl\"] = -Decimal(\"105e6\") + Decimal(\"560444\") * (Decimal(\"1e9\") + data[\"SDR:frep_ErYb\"]) / Decimal(2) - data[\"fb_Al_ErYb\"]\n",
    "    data[\"nuAl\"] = Decimal(4) * data[\"nuAl\"]   \n",
    "\n",
    "# frequency for Sr clock \n",
    "def compute_nuSr_ErYb(data):\n",
    "    data[\"nuSi\"] = -Decimal(\"105e6\") + Decimal(\"388752\") * (Decimal(\"1e9\") + data[\"SDR:frep_ErYb\"]) / Decimal(2) - Decimal(\"100e6\")\n",
    "    data[\"nuSr\"] = (Decimal(\"1716882\") / Decimal(\"777577\")) * (data[\"nuSi\"] - Decimal(\"216e6\"))\n",
    "\n",
    "\n",
    " \n",
    "################################################################################\n",
    "#############################  Load data #######################################\n",
    "################################################################################\n",
    " \n",
    "path = \"/Users/smt3/Documents/GitHub/atomic-clock/st-interp/three_clocks/\"\n",
    "\n",
    "# load comb data\n",
    "data_ErYb = open_ErYb_data(path + \"20240813_Deglitched_ErYb_only1.dat\")\n",
    " \n",
    "# load Al shift data \n",
    "shift_data_Al = open_shiftfile_Al(path + \"20240813_Al+_Freq_Shifts_ErYb.dat\")\n",
    "\n",
    "# load Sr shift data\n",
    "shift_data_Sr = open_shiftfile_Sr(path + \"20240813_Sr_Freq_Shifts.dat\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "################################################################################\n",
    "###############  get optical frequencies #############################\n",
    "################################################################################\n",
    " \n",
    "compute_nuSr_ErYb(data_ErYb)\n",
    "compute_nuAl_ErYb(data_ErYb)\n",
    " \n",
    " \n",
    "\n",
    "################################################################################\n",
    "#########################  Data Processing #####################################\n",
    "################################################################################\n",
    "\n",
    "## Extract only \"IS_GOOD\" data for analysis \n",
    "good_condition_al = shift_data_Al[\"IS_GOOD\"] == 1\n",
    "shift_data_Al_good = shift_data_Al[good_condition_al].reset_index(drop=True)\n",
    "good_condition_sr = shift_data_Sr[\"IS_GOOD\"] == 1\n",
    "shift_data_Sr_good = shift_data_Sr[good_condition_sr].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# ## View frequency of MDJ observations  \n",
    "# shift_data_Al[\"MJD_diff\"] = shift_data_Al.MJD.diff()\n",
    "\n",
    "# series_MJD_Al_diff = shift_data_Al[\"MJD_diff\"]\n",
    "# # plt.hist(series_MJD_Sr_diff.dropna(), bins = 500)\n",
    "# # plt.xlim(0.00005, 0.00025)\n",
    "# # plt.show()\n",
    "\n",
    "# #print(series_MJD_Sr_diff.dtype)\n",
    "# series_MJD_Al_diff.describe()\n",
    "\n",
    "#mode MJD diff for Sr: 0.0001, max diff: 0.001224\n",
    "#mode MJD diff for Al: 0.000012, max diff: 0.018264\n",
    "\n",
    "common_mjd = data_ErYb[\"MJD\"].astype(float)\n",
    "nuAl = data_ErYb[\"nuAl\"].astype(float)\n",
    "nuAl = [Decimal(i) for i in nuAl]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Create low sampling frequency observations of Al and distinguish this from the high sampling case\n",
    "## Do the same for the relevant comb values \n",
    "\n",
    "#function to extract element as close to target as possible w/out going over\n",
    "def lb_extract(target, data):\n",
    "    inx = 0\n",
    "    stopper = 1\n",
    "    while stopper == 1:\n",
    "        if data[inx] <= target:\n",
    "            inx += 1\n",
    "        else:\n",
    "            return inx  \n",
    "\n",
    "#function to extract element as close to target as possible w/out going under \n",
    "def ub_extract(target, data):\n",
    "    inx = 1\n",
    "    stopper = 1\n",
    "    while stopper == 1:\n",
    "        if data[len(data)-inx] >= target:\n",
    "            inx += 1\n",
    "        else:\n",
    "            return len(data)-inx  \n",
    "\n",
    "#### first comb time point:  60535.682346  (# first good Al time point:  60535.6818403)\n",
    "#### last good Al time point:  60535.9108218  (# last comb time point:  60535.911951)\n",
    "\n",
    "len_comb = len(common_mjd) \n",
    "len_Al = len(shift_data_Al_good['MJD'])                  \n",
    "\n",
    "comb_high = pd.DataFrame()\n",
    "comb_end = lb_extract(target = shift_data_Al_good[\"MJD\"][len_Al-1], data = common_mjd)  \n",
    "comb_high[\"MJD\"] = common_mjd[:comb_end]\n",
    "comb_high[\"nuAl\"] = nuAl[:comb_end]\n",
    "\n",
    "al_start = ub_extract(target = common_mjd[0], data = shift_data_Al_good)\n",
    "shift_data_Al_high = shift_data_Al_good[al_start:]\n",
    "\n",
    "\n",
    "inx_low = #sample from grid based on min/max and mode mdj of Al w/ rate of 0.0001\n",
    "\n",
    "comb_low = pd.DataFrame()\n",
    "shift_data_Al_low = shift_data_Al_good[]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#########################  Interpolation             ###########################\n",
    "## Is this even necessary to prove point ? may skip ---\n",
    "################################################################################\n",
    "# shiftAl_low = np.interp(comb_low[\"MJD\"], shift_data_Al_low[\"MJD\"], shift_data_Al_low[\"shift\"])\n",
    "# shiftAl_low = [Decimal(i) for i in shiftAl_low]\n",
    "\n",
    "# shiftAl_high = np.interp(comb_high[\"MJD\"], shift_data_Al_high[\"MJD\"], shift_data_Al_high[\"shift\"])\n",
    "# shiftAl_high = [Decimal(i) for i in shiftAl_high]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#########################  Estimation                ###########################\n",
    "## TODO: calculate AVAR for each set also \n",
    "################################################################################\n",
    "# frequency corrections\n",
    "masercorrection = Decimal(\"-7.36631e-12\")\n",
    "GR_shift_Al = Decimal(\"-8.114e-16\")\n",
    "GR_shift_sea_level = Decimal(\"-1798.501e-16\")\n",
    "total_correction_Al = Decimal(\"1\") + GR_shift_Al + GR_shift_sea_level + masercorrection\n",
    "\n",
    "frequency_Al_ErYb_low = [(i + j) * total_correction_Al for i,j in zip(comb_low[\"nuAl\"], shiftAl_low)]\n",
    "frequency_Al_ErYb_high = [(i + j) * total_correction_Al for i,j in zip(comb_high[\"nuAl\"], shiftAl_high)]\n",
    "print(\"Al+ ave with lower sampling rate\", '{:0.5}'.format(np.nanmean(frequency_Al_ErYb_low)), '\\n' )\n",
    "print(\"Al+ ave with higher sampling rate\", '{:0.5}'.format(np.nanmean(frequency_Al_ErYb_high)) )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
